import fetch from 'node-fetch';
import { ChatEntry } from '../types';

const historyText = `
  Voc√™ √© um modelo de linguagem treinado para fornecer respostas sobre projetos de tecnologia
  Voc√™ representa Cl√°udio Soares que desenvolve solu√ß√µes tecnologicas usando React, Next.js, Node.js, Tailwind CSS, e mais. Trabalho focado em performance e experi√™ncia do usu√°rio. 
  Pre√ßo por projeto fechado ou, em casos espec√≠ficos, por hora. Para entrar em contato, voce pode clicar nos bot√µes de contato na p√°gina.
  Seja amig√°vel!
`;

const contentMessage = `
    Se perguntarem voce √© um modelo de linguagem artificial que vai sanar algumas d√∫vidas das pessoas no chat, e repesenta Cl√°udio Soares desenvolvedor frontend e fullstack do Brasil. 
    Responda de forma breve, amig√°vel e natural, como se estivesse conversando diretamente com um poss√≠vel cliente no chat.
    Use emojis, mas n√£o muitos, apenas para deixar a conversa mais descontraida
`;

export async function servicesAgent(task: string, recentHistory: ChatEntry[]) {
  // Formatar o hist√≥rico recente para incluir no prompt
  const recentQuestionsAndAnswers = recentHistory.map((entry: { question: string, answer: string }) => {
    return `Q: ${entry.question}\nA: ${entry.answer}\n`;
  }).join("\n");

  if (task.includes("falar com voc√™") || task.includes("entrar em contato") || task.includes("reuni√µes")) {
    return "Voce pode entrar em contato atrav√©s dos bot√µes de contatos na p√°gina. üòä";
  };

  const prompt = `
    Hist√≥rico recente: ${recentQuestionsAndAnswers}
    Leve sempre em considera√ß√£o o contexto rescente para responder.
    Quando perguntarem sobre os servi√ßos que voc√™ oferece ou como voc√™ trabalha, use essas informa√ß√µes como base para sua resposta: ${historyText}

    Use respostas curtas e objetivas e nunca forne√ßa pre√ßos de trabalhos, seja educado e objetivo nas respostas
    Tarefa: "${task}"
  `;

  try {
    const response = await fetch(process.env.GROQ_API_URL || "", {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.GROQ_API_KEY}`,
      },
      body: JSON.stringify({
        model: 'llama-3.3-70b-versatile',
        messages: [
          {
            role: 'system',
            content: contentMessage
          },
          {
            role: 'user',
            content: prompt,
          },
        ]
      })
    });

    const data = await response.json();
    const choice = data?.choices?.[0]?.message?.content?.trim();
    if (!choice || choice.length === 0) {
      return "Parece que houve um erro. Pode tentar novamente? Eu estou aqui para ajudar!";
    }
    return { message: choice };
  } catch (error) {
    console.error("Erro ao chamar a API:", error);
    return { message: "Poxa, n√£o consegui entender direito agora. Voc√™ pode tentar perguntar de outro jeito?" };
  }
}
